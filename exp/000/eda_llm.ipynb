{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_number: '000'\n",
      "run_name: base\n",
      "path:\n",
      "  data: ../../data\n",
      "  results: ../../results\n",
      "  train: ../../data/train.csv\n",
      "  test: ../../data/test.csv\n",
      "  sample_submission: ../../data/sample_submission.csv\n",
      "  results_dir: ../../data/000/base\n",
      "seed: 42\n",
      "n_splits: 5\n",
      "target: target\n",
      "plt:\n",
      "  context: notebook\n",
      "  style: whitegrid\n",
      "  palette: Set1\n",
      "  rc:\n",
      "    font.family: sans-serif\n",
      "    figure.figsize:\n",
      "    - 6\n",
      "    - 4\n",
      "    figure.facecolor: white\n",
      "    axes.grid: false\n",
      "    axes.edgecolor: black\n",
      "    axes.facecolor: none\n",
      "    xtick.color: black\n",
      "    ytick.color: black\n",
      "    xtick.direction: in\n",
      "    ytick.direction: in\n",
      "    xtick.major.size: 3\n",
      "    ytick.major.size: 3\n",
      "    xtick.major.width: 1\n",
      "    ytick.major.width: 1\n",
      "    xtick.minor.size: 2\n",
      "    ytick.minor.size: 2\n",
      "    xtick.minor.width: 1\n",
      "    ytick.minor.width: 1\n",
      "    xtick.top: true\n",
      "    ytick.right: true\n",
      "    xtick.major.pad: 2\n",
      "    ytick.major.pad: 2\n",
      "    grid.color: gray\n",
      "    grid.linestyle: --\n",
      "    grid.linewidth: 0.5\n",
      "\n",
      "bf16: True\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import safetensors\n",
    "import seaborn as sns\n",
    "import torch\n",
    "# from dotenv import load_dotenv\n",
    "from hydra import compose, initialize\n",
    "from jinja2 import Template\n",
    "from matplotlib import pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from peft import LoraConfig, PeftConfig, PeftModel, TaskType, get_peft_model, prepare_model_for_kbit_training\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from src.seed import seed_everything\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,  # AutoModelForCausalLM: 次の単語を予測するモデル\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.utils import is_torch_bf16_gpu_available\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "with initialize(config_path=\"config\", version_base=None):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    cfg.exp_number = Path().resolve().name\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "# seed_everything(cfg.seed)\n",
    "\n",
    "# .envファイルから環境変数を読み込む\n",
    "# load_dotenv()\n",
    "\n",
    "# bf16が使えるか確認\n",
    "print(f\"bf16: {is_torch_bf16_gpu_available()}\")\n",
    "\n",
    "# デバイスの指定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d3cdc3d70a4be796bf0968337368bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
